"""
Parser de Exames com Claude Haiku
Extrai, normaliza e deduplica resultados de exames
Economia estimada: ~66% vs Claude Sonnet
"""

import re
import json
import uuid
from typing import List, Dict, Any
from src.config import (
    CLAUDE_HAIKU_MODEL,
    CLAUDE_MAX_TOKENS,
    CLAUDE_TEMPERATURE,
    EXAM_NAME_SIMILARITY_THRESHOLD
)


def parse_exams_from_text(extracted_text: str, anthropic_client) -> List[Dict[str, Any]]:
    """
    Parseia exames usando Claude Haiku com prompt otimizado
    Processa documentos completos com chunking automÃ¡tico
    
    Args:
        extracted_text: Texto extraÃ­do do PDF
        anthropic_client: Cliente Anthropic
        
    Returns:
        Lista de exames estruturados
    """
    # Processar texto completo em chunks se necessÃ¡rio
    max_chunk_size = 12000  # ~3000 tokens
    
    if len(extracted_text) > max_chunk_size:
        print(f'ğŸ“„ Documento longo detectado: {len(extracted_text)} caracteres')
        return _parse_long_document(extracted_text, anthropic_client, max_chunk_size)
    else:
        return _parse_single_chunk(extracted_text, anthropic_client)


def _parse_single_chunk(text: str, anthropic_client) -> List[Dict[str, Any]]:
    """Parseia um Ãºnico chunk de texto"""
    
    # Lista de biomarcadores vÃ¡lidos (top 80 mais comuns)
    valid_biomarkers = """
BIOMARCADORES VÃLIDOS (use nomes padronizados):
- GLICEMIA JEJUM, HbA1c, INSULINA, HOMA IR, PEPTÃDEO C
- CT (Colesterol Total), LDL, HDL, VLDL, TG (TriglicÃ©rides)
- CREATININA, URÃ‰IA, TFG CKD-EPI, ÃCIDO ÃšRICO
- TGO/AST, TGP/ALT, GGT, FA (Fosfatase Alcalina), ALBUMINA
- TSH, T3 LIVRE, T4 LIVRE, T3 TOTAL, T4 TOTAL
- TESTOSTERONA TOTAL, TESTOSTERONA LIVRE, ESTRADIOL, PROGESTERONA
- CORTISOL, DHEA-S, PROLACTINA, LH, FSH
- 25-OH VIT D, VIT B12, ÃCIDO FÃ“LICO, FERRITINA, FERRO
- PCR ULTRA SENSÃVEL, VHS, HOMOCISTEÃNA, FIBRINOGÃŠNIO
- HEMOGLOBINA, HEMATÃ“CRITO, HEMÃCIAS, LEUCÃ“CITOS, PLAQUETAS
- NEUTRÃ“FILOS, LINFÃ“CITOS, MONÃ“CITOS, EOSINÃ“FILOS, BASÃ“FILOS
- VCM, HCM, CHCM, RDW
- PSA TOTAL, PSA LIVRE, CEA, CA 125, CA 19-9
- SÃ“DIO, POTÃSSIO, CÃLCIO, MAGNÃ‰SIO, FÃ“SFORO, CLORO
- PROTEÃNAS TOTAIS, BILIRRUBINA TOTAL, BBD, BBI
"""
    
    prompt = f"""VocÃª Ã© um extrator especializado de laudos laboratoriais. Analise o laudo e extraia TODOS os biomarcadores.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
REGRAS CRÃTICAS DE EXTRAÃ‡ÃƒO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. **FORMATO DE SAÃDA**: Retorne APENAS um array JSON vÃ¡lido. Nenhum texto antes ou depois.

2. **VALIDAÃ‡Ã•ES OBRIGATÃ“RIAS**:
   âŒ "LaboratÃ³rio XYZ" NÃƒO Ã© nome de pessoa
   âŒ "Data de Nascimento" NÃƒO Ã© data do exame
   âŒ Ignore cabeÃ§alhos, rodapÃ©s e informaÃ§Ãµes administrativas
   âœ… Extraia apenas valores de biomarcadores laboratoriais

3. **EXPANSÃƒO DE EXAMES COMPOSTOS** (CRÃTICO):
   - Se encontrar "Hemograma Completo", extraia 13+ biomarcadores individuais:
     HemÃ¡cias, Hemoglobina, HematÃ³crito, VCM, HCM, CHCM, RDW,
     LeucÃ³citos, NeutrÃ³filos, LinfÃ³citos, MonÃ³citos, EosinÃ³filos, BasÃ³filos, Plaquetas
   
   - Se encontrar "Lipidograma", extraia 5 biomarcadores:
     Colesterol Total (CT), LDL, HDL, VLDL, TriglicÃ©rides (TG)
   
   - Se encontrar "FunÃ§Ã£o Renal", extraia:
     Creatinina, Ureia, TFG CKD-EPI, Ãcido Ãšrico
   
   - Se encontrar "FunÃ§Ã£o HepÃ¡tica", extraia:
     TGO/AST, TGP/ALT, GGT, Fosfatase Alcalina, Bilirrubinas, Albumina

4. **EXTRAÃ‡ÃƒO DE VALORES NUMÃ‰RICOS**:
   âœ… "95.5" â†’ extraia "95.5"
   âœ… "38.0 mm/h" â†’ value: "38.0", unit: "mm/h"
   âœ… "< 1.0" â†’ extraia "< 1.0" (manter operadores)
   âœ… "Positivo" ou "Negativo" â†’ extraia como string

5. **VALORES DE REFERÃŠNCIA**:
   âœ… "10-50" â†’ reference_min: "10", reference_max: "50"
   âœ… "atÃ© 20" â†’ reference_min: null, reference_max: "20"
   âœ… ">= 30" â†’ reference_min: "30", reference_max: null
   âœ… Sempre extraia como strings, nÃ£o como nÃºmeros

6. **STATUS DO EXAME**:
   - Se valor estiver ABAIXO do normal â†’ "baixo"
   - Se valor estiver DENTRO do normal â†’ "normal"
   - Se valor estiver ACIMA do normal â†’ "alto"
   - Se nÃ£o houver referÃªncia â†’ "sem_referencia"

{valid_biomarkers}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FORMATO JSON DE SAÃDA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[
  {{
    "exam_name": "VHS",
    "value": "38.0",
    "unit": "mm/h",
    "reference_min": "0",
    "reference_max": "20",
    "status": "alto",
    "method": "Westergren",
    "observation": null
  }},
  {{
    "exam_name": "GLICEMIA JEJUM",
    "value": "95",
    "unit": "mg/dL",
    "reference_min": "70",
    "reference_max": "99",
    "status": "normal",
    "method": null,
    "observation": null
  }},
  {{
    "exam_name": "HEMOGLOBINA",
    "value": "14.2",
    "unit": "g/dL",
    "reference_min": "12.0",
    "reference_max": "16.0",
    "status": "normal",
    "method": null,
    "observation": null
  }}
]

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
LAUDO A PROCESSAR
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{text[:12000]}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RESPOSTA (SOMENTE JSON)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"""
    
    try:
        message = anthropic_client.messages.create(
            model=CLAUDE_HAIKU_MODEL,
            max_tokens=CLAUDE_MAX_TOKENS,
            temperature=CLAUDE_TEMPERATURE,
            messages=[{"role": "user", "content": prompt}]
        )
        
        response_text = message.content[0].text
        
        # Extrair JSON da resposta
        json_match = re.search(r'\[.*\]', response_text, re.DOTALL)
        if json_match:
            exams = json.loads(json_match.group(0))
            print(f'âœ… Claude Haiku: {len(exams)} biomarcadores extraÃ­dos')
            return exams
        else:
            print('âš ï¸ Claude Haiku: Resposta sem JSON vÃ¡lido')
            return []
        
    except Exception as e:
        print(f'âŒ Claude Haiku falhou: {e}')
        import traceback
        traceback.print_exc()
        return []


def _parse_long_document(text: str, anthropic_client, chunk_size: int) -> List[Dict[str, Any]]:
    """
    Parseia documentos longos dividindo em chunks com overlap
    Evita perder biomarcadores nas bordas dos chunks
    """
    overlap = 1000  # 1000 chars de overlap entre chunks
    chunks = []
    
    # Dividir texto em chunks com overlap
    for i in range(0, len(text), chunk_size - overlap):
        chunk = text[i:i + chunk_size]
        chunks.append(chunk)
    
    print(f'ğŸ“¦ Processando {len(chunks)} chunks com overlap...')
    
    all_exams = []
    seen_exams = set()  # Para deduplicar entre chunks
    
    for idx, chunk in enumerate(chunks):
        print(f'ğŸ”„ Processando chunk {idx + 1}/{len(chunks)}...')
        chunk_exams = _parse_single_chunk(chunk, anthropic_client)
        
        # Adicionar apenas exames Ãºnicos (evitar duplicatas do overlap)
        for exam in chunk_exams:
            exam_key = f"{exam.get('exam_name', '')}-{exam.get('value', '')}"
            if exam_key not in seen_exams:
                all_exams.append(exam)
                seen_exams.add(exam_key)
    
    print(f'âœ… Total de biomarcadores extraÃ­dos de todos os chunks: {len(all_exams)}')
    return all_exams


def clean_reference_values(exames: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Normaliza valores de referÃªncia (min/max)
    
    Args:
        exames: Lista de exames brutos
        
    Returns:
        Lista de exames com referÃªncias normalizadas
    """
    for exam in exames:
        # Garantir que reference_min e reference_max sejam float ou None
        for field in ['reference_min', 'reference_max']:
            value = exam.get(field)
            
            if value is None or value == '':
                exam[field] = None
            elif isinstance(value, str):
                # Limpar string e converter
                clean_value = value.strip().replace(',', '.')
                try:
                    exam[field] = float(clean_value)
                except ValueError:
                    exam[field] = None
            elif isinstance(value, (int, float)):
                exam[field] = float(value)
        
        # Garantir que value seja numÃ©rico quando possÃ­vel
        value = exam.get('value')
        if isinstance(value, str):
            clean_value = value.strip().replace(',', '.')
            # Remover unidades que possam estar grudadas
            clean_value = re.sub(r'[a-zA-Z/%]+$', '', clean_value).strip()
            try:
                exam['value'] = float(clean_value)
            except ValueError:
                pass  # Manter como string se nÃ£o for conversÃ­vel
    
    return exames


def deduplicate_exams(exames: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Remove exames duplicados, mantendo o mais completo
    
    Args:
        exames: Lista de exames (pode ter duplicatas)
        
    Returns:
        Lista dedupilcada
    """
    from difflib import SequenceMatcher
    
    def are_similar(name1: str, name2: str, threshold: float = EXAM_NAME_SIMILARITY_THRESHOLD) -> bool:
        """Verifica se dois nomes de exames sÃ£o similares"""
        n1 = name1.lower().strip()
        n2 = name2.lower().strip()
        return SequenceMatcher(None, n1, n2).ratio() >= threshold
    
    def completeness_score(exam: Dict[str, Any]) -> int:
        """Calcula pontuaÃ§Ã£o de completude de um exame"""
        score = 0
        if exam.get('value') not in [None, '']:
            score += 10
        if exam.get('reference_min') is not None:
            score += 5
        if exam.get('reference_max') is not None:
            score += 5
        if exam.get('unit'):
            score += 3
        if exam.get('status'):
            score += 2
        if exam.get('method'):
            score += 1
        return score
    
    # Agrupar exames similares
    groups = []
    for exam in exames:
        exam_name = exam.get('exam_name', '')
        
        # Tentar adicionar a um grupo existente
        added = False
        for group in groups:
            if are_similar(group[0]['exam_name'], exam_name):
                group.append(exam)
                added = True
                break
        
        # Criar novo grupo se necessÃ¡rio
        if not added:
            groups.append([exam])
    
    # Manter o mais completo de cada grupo
    deduplicated = []
    for group in groups:
        if len(group) == 1:
            deduplicated.append(group[0])
        else:
            # Ordenar por completude e pegar o melhor
            sorted_group = sorted(group, key=completeness_score, reverse=True)
            deduplicated.append(sorted_group[0])
            print(f'ğŸ”„ Deduplicado: {sorted_group[0]["exam_name"]} ({len(group)} versÃµes)')
    
    print(f'âœ… DeduplicaÃ§Ã£o: {len(exames)} -> {len(deduplicated)} exames')
    return deduplicated


def assign_biomarker_ids(exames: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Adiciona IDs Ãºnicos a cada exame
    
    Args:
        exames: Lista de exames
        
    Returns:
        Lista de exames com biomarker_id
    """
    for exam in exames:
        if 'biomarker_id' not in exam:
            exam['biomarker_id'] = str(uuid.uuid4())
    
    return exames
